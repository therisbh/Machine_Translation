{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMD6xnCdWl3yBQNr1yRzJQP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/therisbh/Machine_Translation/blob/main/Natural_machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install & Imports"
      ],
      "metadata": {
        "id": "ilmx606MIh0B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIgcVxY1IRJm",
        "outputId": "35119eef-3632-4af6-b51c-4c339d182bf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/100.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q sentencepiece datasets sacrebleu\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import sentencepiece as spm\n",
        "from datasets import load_dataset\n",
        "import random\n"
      ],
      "metadata": {
        "id": "wyJY5_sqIjwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTh2Mgq0JWea",
        "outputId": "79e3a894-2940-4c59-bcb7-170475ff159e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load & Subset Dataset"
      ],
      "metadata": {
        "id": "n5e5gAlrIonK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset = load_dataset(\"cfilt/iitb-english-hindi\")"
      ],
      "metadata": {
        "id": "tsqZU6q6OCEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[\"train\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObPZOgi9OEZc",
        "outputId": "fd5ee614-7a30-4d83-9bfe-6c76dc06d2ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'translation': {'en': 'Give your application an accessibility workout', 'hi': 'अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LINES = 150000\n",
        "\n",
        "en_all = []\n",
        "hi_all = []\n",
        "\n",
        "for i in range(MAX_LINES):\n",
        "    item = dataset[\"train\"][i]\n",
        "    en_all.append(item[\"translation\"][\"en\"])\n",
        "    hi_all.append(item[\"translation\"][\"hi\"])\n",
        "\n",
        "en_train, en_test, hi_train, hi_test = train_test_split(\n",
        "    en_all, hi_all, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(en_train))\n",
        "print(\"Test size:\", len(en_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1t5nO2BItY2",
        "outputId": "5b502734-e1b7-49c6-9c87-300c5706bbf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 135000\n",
            "Test size: 15000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[\"train\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHc1vRnzNS_i",
        "outputId": "3c3ac2cd-7a2d-483c-e7cf-dfb830314af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'translation': {'en': 'Give your application an accessibility workout', 'hi': 'अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data for SentencePiece"
      ],
      "metadata": {
        "id": "NiswyZ62JdBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"spm_train.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for e, h in zip(en_train, hi_train):\n",
        "        f.write(e.strip() + \"\\n\")\n",
        "        f.write(h.strip() + \"\\n\")\n"
      ],
      "metadata": {
        "id": "McYOhuf4Jesz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train SentencePiece"
      ],
      "metadata": {
        "id": "lkBQG_7TJhyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spm.SentencePieceTrainer.train(\n",
        "    input=\"spm_train.txt\",\n",
        "    model_prefix=\"spm_bpe\",\n",
        "    vocab_size=10000,\n",
        "    model_type=\"bpe\",\n",
        "    character_coverage=1.0,\n",
        "    pad_id=0,\n",
        "    unk_id=1,\n",
        "    bos_id=2,\n",
        "    eos_id=3\n",
        ")\n"
      ],
      "metadata": {
        "id": "RLcG8MXuJiba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load SentencePiece Model"
      ],
      "metadata": {
        "id": "1MlqEfJBJl7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(\"spm_bpe.model\")\n",
        "\n",
        "PAD, UNK, BOS, EOS = 0, 1, 2, 3\n",
        "VOCAB_SIZE = sp.get_piece_size()\n",
        "\n",
        "print(\"Vocab size:\", VOCAB_SIZE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAKOrH-nJoMp",
        "outputId": "f89ae36b-45fd-479f-9765-e5f13817a33e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Class"
      ],
      "metadata": {
        "id": "SawU9JfAJqpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src, tgt, max_len=30):\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def encode(self, sentence):\n",
        "        ids = [BOS] + sp.encode(sentence, out_type=int) + [EOS]\n",
        "        return ids[:self.max_len]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            torch.tensor(self.encode(self.src[idx])),\n",
        "            torch.tensor(self.encode(self.tgt[idx]))\n",
        "        )\n"
      ],
      "metadata": {
        "id": "EeEYlcYWJs7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collate Function"
      ],
      "metadata": {
        "id": "8Mir1iTFJvYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    src, tgt = zip(*batch)\n",
        "    src = pad_sequence(src, batch_first=True, padding_value=PAD)\n",
        "    tgt = pad_sequence(tgt, batch_first=True, padding_value=PAD)\n",
        "    return src, tgt\n"
      ],
      "metadata": {
        "id": "Q1Jv0MjYJvI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "12Vest9xJ0Si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TranslationDataset(en_train, hi_train)\n",
        "test_dataset  = TranslationDataset(en_test, hi_test)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n"
      ],
      "metadata": {
        "id": "a8YjAg9VJz1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "gJdCX4ahJ5OK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD)\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        outputs, hidden = self.rnn(emb)\n",
        "        return outputs, hidden\n"
      ],
      "metadata": {
        "id": "ngqLU4WPJ6qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(VOCAB_SIZE, 256, 512).to(device)\n",
        "print(encoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNPbX8qOQodd",
        "outputId": "be951eb8-fd68-4a5f-99f2-8563f1cc3bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder(\n",
            "  (embedding): Embedding(10000, 256, padding_idx=0)\n",
            "  (rnn): GRU(256, 512, batch_first=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vanilla Decoder"
      ],
      "metadata": {
        "id": "ag4iw-n_LjmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VanillaDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD)\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hid_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        emb = self.embedding(x)\n",
        "        output, hidden = self.rnn(emb, hidden)\n",
        "        output = self.fc(output.squeeze(1))\n",
        "        return output, hidden\n"
      ],
      "metadata": {
        "id": "chzLJACeLhiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vanilla_decoder = VanillaDecoder(VOCAB_SIZE, 256, 512).to(device)\n",
        "\n",
        "optimizer_vanilla = optim.Adam(\n",
        "    list(encoder.parameters()) + list(vanilla_decoder.parameters()),\n",
        "    lr=0.001\n",
        ")\n",
        "\n",
        "def train_epoch_vanilla():\n",
        "    encoder.train()\n",
        "    vanilla_decoder.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for src, tgt in train_loader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer_vanilla.zero_grad()\n",
        "\n",
        "        enc_out, hidden = encoder(src)\n",
        "        input_tok = tgt[:, 0].unsqueeze(1)\n",
        "\n",
        "        loss = 0\n",
        "        for t in range(1, tgt.size(1)):\n",
        "            output, hidden = vanilla_decoder(input_tok, hidden)\n",
        "            loss += criterion(output, tgt[:, t])\n",
        "            input_tok = tgt[:, t].unsqueeze(1)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), 1.0)\n",
        "        optimizer_vanilla.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_loader)\n"
      ],
      "metadata": {
        "id": "SvlYLU_ALrE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Vanilla Model"
      ],
      "metadata": {
        "id": "ZObcBq_iL25F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD)"
      ],
      "metadata": {
        "id": "4d_YVQtSROhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Vanilla Encoder–Decoder\")\n",
        "\n",
        "for epoch in range(10):\n",
        "    loss = train_epoch_vanilla()\n",
        "    print(f\"[Vanilla] Epoch {epoch+1} | Loss: {loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vB11O_5L6h9",
        "outputId": "da48d00b-53eb-4457-b75e-49136cf7cb54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Vanilla Encoder–Decoder\n",
            "[Vanilla] Epoch 1 | Loss: 79.4926\n",
            "[Vanilla] Epoch 2 | Loss: 25.4579\n",
            "[Vanilla] Epoch 3 | Loss: 13.3244\n",
            "[Vanilla] Epoch 4 | Loss: 8.8935\n",
            "[Vanilla] Epoch 5 | Loss: 6.7948\n",
            "[Vanilla] Epoch 6 | Loss: 6.1329\n",
            "[Vanilla] Epoch 7 | Loss: 5.3259\n",
            "[Vanilla] Epoch 8 | Loss: 4.9544\n",
            "[Vanilla] Epoch 9 | Loss: 4.8974\n",
            "[Vanilla] Epoch 10 | Loss: 4.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_token_accuracy(encoder, decoder, test_loader):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in test_loader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "\n",
        "            enc_out, hidden = encoder(src)\n",
        "            input_tok = tgt[:, 0].unsqueeze(1)\n",
        "\n",
        "            for t in range(1, tgt.size(1)):\n",
        "                if isinstance(decoder, VanillaDecoder):\n",
        "                    output, hidden = decoder(input_tok, hidden)\n",
        "                else:\n",
        "                    output, hidden = decoder(input_tok, hidden, enc_out)\n",
        "\n",
        "                preds = output.argmax(1)\n",
        "                mask = tgt[:, t] != PAD\n",
        "\n",
        "                correct += (preds[mask] == tgt[:, t][mask]).sum().item()\n",
        "                total += mask.sum().item()\n",
        "\n",
        "                input_tok = preds.unsqueeze(1)\n",
        "\n",
        "    return correct / total\n"
      ],
      "metadata": {
        "id": "K7RmR9zieK8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vanilla Test Evaluation"
      ],
      "metadata": {
        "id": "RWHo4QqfeQNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating Vanilla Encoder–Decoder on Test Set...\")\n",
        "\n",
        "vanilla_acc = evaluate_token_accuracy(\n",
        "    encoder,\n",
        "    vanilla_decoder,\n",
        "    test_loader\n",
        ")\n",
        "\n",
        "print(f\"Vanilla Seq2Seq Test Accuracy: {vanilla_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ktBlVdFeRJM",
        "outputId": "9e1cdcc6-c588-4e15-d606-581b65c4a639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Vanilla Encoder–Decoder on Test Set...\n",
            "Vanilla Seq2Seq Test Accuracy: 3.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Luong Attention"
      ],
      "metadata": {
        "id": "bEycP120J93V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LuongAttention(nn.Module):\n",
        "    def forward(self, decoder_hidden, encoder_outputs):\n",
        "        # decoder_hidden: (B, H)\n",
        "        # encoder_outputs: (B, T, H)\n",
        "        scores = torch.bmm(\n",
        "            encoder_outputs,\n",
        "            decoder_hidden.unsqueeze(2)\n",
        "        ).squeeze(2)\n",
        "\n",
        "        attn_weights = torch.softmax(scores, dim=1)\n",
        "\n",
        "        context = torch.bmm(\n",
        "            attn_weights.unsqueeze(1),\n",
        "            encoder_outputs\n",
        "        ).squeeze(1)\n",
        "\n",
        "        return context\n"
      ],
      "metadata": {
        "id": "bvyQpDBHKAsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder with Luong Attention"
      ],
      "metadata": {
        "id": "BVbxi5OaKE3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD)\n",
        "        self.attn = LuongAttention()\n",
        "        self.rnn = nn.GRU(emb_dim + hid_dim, hid_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hid_dim * 2, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden, encoder_outputs):\n",
        "        emb = self.embedding(x).squeeze(1)\n",
        "        context = self.attn(hidden.squeeze(0), encoder_outputs)\n",
        "        rnn_input = torch.cat([emb, context], dim=1).unsqueeze(1)\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "        output = self.fc(torch.cat([output.squeeze(1), context], dim=1))\n",
        "        return output, hidden\n"
      ],
      "metadata": {
        "id": "zBf9KrjoKHVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Model"
      ],
      "metadata": {
        "id": "vb-5Ymm5KJVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(VOCAB_SIZE, 256, 512).to(device)\n",
        "decoder = Decoder(VOCAB_SIZE, 256, 512).to(device)\n",
        "\n",
        "optimizer = optim.Adam(\n",
        "    list(encoder.parameters()) + list(decoder.parameters()),\n",
        "    lr=0.001\n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD)\n"
      ],
      "metadata": {
        "id": "gA4GMSDyKK3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Function"
      ],
      "metadata": {
        "id": "E_DefPCsKMhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch():\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for src, tgt in train_loader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        enc_out, hidden = encoder(src)\n",
        "        input_tok = tgt[:, 0].unsqueeze(1)\n",
        "\n",
        "        loss = 0\n",
        "        for t in range(1, tgt.size(1)):\n",
        "            output, hidden = decoder(input_tok, hidden, enc_out)\n",
        "            loss += criterion(output, tgt[:, t])\n",
        "            input_tok = tgt[:, t].unsqueeze(1)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n"
      ],
      "metadata": {
        "id": "avx_N8wZKOcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "d9Nzv0eAKQXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    loss = train_epoch()\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r-NBS5zKTHI",
        "outputId": "103e6e03-9f7b-44d7-d4cb-1efc37ea9ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 158269.2581\n",
            "Epoch 2/10 | Loss: 54377.7760\n",
            "Epoch 3/10 | Loss: 33292.8532\n",
            "Epoch 4/10 | Loss: 25145.8430\n",
            "Epoch 5/10 | Loss: 21582.9462\n",
            "Epoch 6/10 | Loss: 19697.3691\n",
            "Epoch 7/10 | Loss: 20280.4798\n",
            "Epoch 8/10 | Loss: 19168.1870\n",
            "Epoch 9/10 | Loss: 20376.8965\n",
            "Epoch 10/10 | Loss: 19516.3468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention Accuracy Test"
      ],
      "metadata": {
        "id": "qKea3WVBgs87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating Seq2Seq + Luong Attention on Test Set...\")\n",
        "\n",
        "attention_acc = evaluate_token_accuracy(\n",
        "    encoder,\n",
        "    decoder,   # Luong attention decoder\n",
        "    test_loader\n",
        ")\n",
        "\n",
        "print(f\"Luong Attention Test Accuracy: {attention_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JxtMGx_gKRW",
        "outputId": "2baa86b6-321b-412b-8d65-3b30ec5674dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Seq2Seq + Luong Attention on Test Set...\n",
            "Luong Attention Test Accuracy: 57.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing on my custom text"
      ],
      "metadata": {
        "id": "ky6YKtwMl8SG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_custom_sentence(sentence, encoder, decoder, max_len=30):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Encode input sentence\n",
        "        src_ids = [BOS] + sp.encode(sentence, out_type=int) + [EOS]\n",
        "        src = torch.tensor(src_ids).unsqueeze(0).to(device)\n",
        "\n",
        "        enc_out, hidden = encoder(src)\n",
        "\n",
        "        # Start decoding\n",
        "        input_tok = torch.tensor([[BOS]]).to(device)\n",
        "        output_ids = []\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            if isinstance(decoder, VanillaDecoder):\n",
        "                output, hidden = decoder(input_tok, hidden)\n",
        "            else:\n",
        "                output, hidden = decoder(input_tok, hidden, enc_out)\n",
        "\n",
        "            pred = output.argmax(1).item()\n",
        "\n",
        "            if pred == EOS:\n",
        "                break\n",
        "\n",
        "            output_ids.append(pred)\n",
        "            input_tok = torch.tensor([[pred]]).to(device)\n",
        "\n",
        "    return sp.decode(output_ids)\n"
      ],
      "metadata": {
        "id": "jKDdlt7Hl_kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_sentence = \"I am learning machine learning\"\n",
        "\n",
        "print(\"Input (English):\", custom_sentence)\n",
        "\n",
        "print(\"\\nVanilla Seq2Seq Output:\")\n",
        "print(translate_custom_sentence(custom_sentence, encoder, vanilla_decoder))\n",
        "\n",
        "print(\"\\nLuong Attention Output:\")\n",
        "print(translate_custom_sentence(custom_sentence, encoder, decoder))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwqSuCsSmCgv",
        "outputId": "32f1aa69-d4f0-4d46-a192-9be679c8cc5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input (English): I am learning machine learning\n",
            "\n",
            "Vanilla Seq2Seq Output:\n",
            "उपफ़ोल्डर रखने के लिए, सूचना के गुण में बताता हैं% s\n",
            "\n",
            "Luong Attention Output:\n",
            "स्ट्रिंग स्थानीय\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = [\n",
        "    \"I am going to school\",\n",
        "    \"She is reading a book\",\n",
        "    \"Machine learning is very interesting\",\n",
        "    \"I love studying artificial intelligence\"\n",
        "]\n",
        "\n",
        "for s in test_sentences:\n",
        "    print(\"\\nEnglish:\", s)\n",
        "    print(\"Hindi (Attention):\", translate_custom_sentence(s, encoder, vanilla_decoder))\n",
        "\n",
        "    print(\"\\nEnglish:\", s)\n",
        "    print(\"Hindi (Loung):\", translate_custom_sentence(s, encoder, decoder))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPMqSmGTmIe-",
        "outputId": "5137c715-dda4-4db2-d031-137d38f0acad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English: I am going to school\n",
            "Hindi (Attention): ेटा हुआ है.\n",
            "\n",
            "English: I am going to school\n",
            "Hindi (Loung): रद्दी में फ़ाइल को रद्दी और फिर से चालू करे\n",
            "\n",
            "English: She is reading a book\n",
            "Hindi (Attention): इस लिंक _ भ्रिकोण\n",
            "\n",
            "English: She is reading a book\n",
            "Hindi (Loung): किताब किताब% s\n",
            "\n",
            "English: Machine learning is very interesting\n",
            "Hindi (Attention): स्वतः आकार की जाँच करें\n",
            "\n",
            "English: Machine learning is very interesting\n",
            "Hindi (Loung): संदेश में भेज रहा है शब्द को आयात करने की जरूरत है\n",
            "\n",
            "English: I love studying artificial intelligence\n",
            "Hindi (Attention): % s में आ रहा है.\n",
            "\n",
            "English: I love studying artificial intelligence\n",
            "Hindi (Loung): यह संचेस के पास कि कोई भी अतिरिक्त में जोड़ें\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## saving model\n"
      ],
      "metadata": {
        "id": "pRcwMXn0nUI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    \"encoder\": encoder.state_dict(),\n",
        "    \"decoder\": vanilla_decoder.state_dict()\n",
        "}, \"vanilla_seq2seq.pth\")\n"
      ],
      "metadata": {
        "id": "l4AtmB6HnT1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    \"encoder\": encoder.state_dict(),\n",
        "    \"decoder\": decoder.state_dict()\n",
        "}, \"attention_seq2seq.pth\")\n"
      ],
      "metadata": {
        "id": "15bZQ0A2nYwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A37BLEUtnab9",
        "outputId": "68c2bd3a-87d0-4ffb-d0ec-1905d8d83622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp attention_seq2seq.pth /content/drive/MyDrive/\n",
        "!cp spm_bpe.model /content/drive/MyDrive/\n",
        "!cp spm_bpe.vocab /content/drive/MyDrive/\n"
      ],
      "metadata": {
        "id": "Vz-XxVsYn9OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Model Configuration"
      ],
      "metadata": {
        "id": "FbAYLeDuoAxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = {\n",
        "    \"vocab_size\": VOCAB_SIZE,\n",
        "    \"embedding_dim\": 256,\n",
        "    \"hidden_dim\": 512,\n",
        "    \"model_type\": \"Seq2Seq + Luong Attention\",\n",
        "    \"tokenizer\": \"SentencePiece BPE\"\n",
        "}\n",
        "\n",
        "torch.save(model_config, \"model_config.pth\")\n",
        "!cp model_config.pth /content/drive/MyDrive/\n"
      ],
      "metadata": {
        "id": "tpJ-XLmQoCa9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}